{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QUESTIONS`\n",
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?\n",
    "\n",
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "\n",
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ANSWERS`\n",
    "Q1: Overfitting in machine learning occurs when a model learns the training data too well, including noise or random fluctuations, leading to poor generalization on new data. Underfitting, on the other hand, happens when a model is too simple and fails to capture the underlying patterns in the data. Consequences of overfitting include poor performance on new data, while underfitting results in a model that performs poorly on both training and new data. To mitigate overfitting, techniques like regularization and cross-validation can be employed.\n",
    "\n",
    "Q2: To reduce overfitting, you can use techniques such as regularization (L1 or L2), dropout, early stopping, and increasing the amount of training data. These methods help prevent the model from fitting the noise in the training data and promote better generalization to new, unseen data.\n",
    "\n",
    "Q3: Underfitting occurs when a model is too simplistic to capture the underlying patterns in the data. This can happen when the model is too simple, the training duration is insufficient, or the data is too complex. Underfitting scenarios include using a linear model for a non-linear problem or having too few features to represent the underlying patterns.\n",
    "\n",
    "Q4: The bias-variance tradeoff in machine learning refers to the balance between bias (error from overly simplistic assumptions) and variance (sensitivity to fluctuations in the training data). Increasing model complexity reduces bias but increases variance, and vice versa. Striking the right balance is crucial for optimal model performance.\n",
    "\n",
    "Q5: Common methods for detecting overfitting and underfitting include cross-validation, analyzing learning curves, and using validation datasets. Overfitting is often indicated by a model performing well on training data but poorly on new data. Underfitting is recognized by poor performance on both training and new data.\n",
    "\n",
    "Q6: Bias represents errors due to overly simplistic assumptions, while variance reflects the model's sensitivity to fluctuations in the training data. High bias models, like simple linear models, may oversimplify and miss underlying patterns. High variance models, like complex deep neural networks, can capture noise and perform poorly on new data due to overfitting.\n",
    "\n",
    "Q7: Regularization in machine learning involves adding a penalty term to the model's objective function to prevent overfitting. Common regularization techniques include L1 and L2 regularization, which penalize large weights, and dropout, which randomly drops units during training to prevent reliance on specific features. These techniques help control model complexity and improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
