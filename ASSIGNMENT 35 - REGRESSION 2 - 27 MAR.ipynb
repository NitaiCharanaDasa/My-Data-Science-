{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QUESTIONS`\n",
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?\n",
    "\n",
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared. \n",
    "\n",
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?\n",
    "\n",
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "\n",
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?\n",
    "\n",
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate.\n",
    "\n",
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.\n",
    "\n",
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ANSWERS`\n",
    "Q1: R-squared in linear regression models represents the proportion of the variance in the dependent variable that is explained by the independent variables. It is calculated as the ratio of the explained variance to the total variance.\n",
    "\n",
    "Q2: Adjusted R-squared considers the number of predictors in the model, adjusting for the risk of overfitting. It penalizes the inclusion of irrelevant variables and generally provides a more accurate measure of model fit when multiple predictors are involved.\n",
    "\n",
    "Q3: Adjusted R-squared is more appropriate when comparing models with different numbers of predictors. It helps to account for the possibility that adding more predictors might increase R-squared by chance.\n",
    "\n",
    "Q4: RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error) are metrics used in regression analysis to measure the difference between predicted and actual values. RMSE is the square root of the average squared differences, MSE is the average squared differences, and MAE is the average absolute differences.\n",
    "\n",
    "Q5: Advantages of RMSE, MSE, and MAE include simplicity and sensitivity to different types of errors. Disadvantages include sensitivity to outliers (RMSE and MSE) and the inability to interpret the error scale consistently (MSE).\n",
    "\n",
    "Q6: Lasso regularization adds a penalty term based on the absolute values of the coefficients, encouraging sparsity and feature selection. It differs from Ridge regularization, which uses the squared values of the coefficients. Lasso is more appropriate when there is a desire to perform feature selection.\n",
    "\n",
    "Q7: Regularized linear models prevent overfitting by adding penalty terms to the model's objective function, discouraging overly complex models. For example, Lasso regularization can force some coefficients to be exactly zero, effectively selecting a subset of features.\n",
    "\n",
    "Q8: Limitations of regularized linear models include sensitivity to the choice of regularization strength, the potential for loss of interpretability, and challenges in handling highly correlated predictors.\n",
    "\n",
    "Q9: Choosing between Model A and Model B depends on the specific goals. RMSE focuses on larger errors, while MAE considers all errors equally. If larger errors are more critical, Model A might be preferred. Limitations include potential bias towards larger errors with RMSE.\n",
    "\n",
    "Q10: Choosing between Ridge and Lasso regularization depends on the context. If feature selection is important, Lasso might be preferred due to its ability to force some coefficients to zero. The choice involves trade-offs, and the optimal regularization method may vary based on the dataset and problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
