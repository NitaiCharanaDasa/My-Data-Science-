{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q1. **What is Bayes' theorem?**\n",
    "Bayes' theorem, named after Reverend Thomas Bayes, is a fundamental theorem in probability theory. It describes the probability of an event based on prior knowledge of conditions that might be related to the event. In essence, Bayes' theorem allows us to update probabilities based on new evidence.\n",
    "\n",
    "Q2. **What is the formula for Bayes' theorem?**\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the probability of event A given that event B has occurred.\n",
    "- \\( P(B|A) \\) is the probability of event B given that event A has occurred.\n",
    "- \\( P(A) \\) and \\( P(B) \\) are the probabilities of events A and B, respectively.\n",
    "\n",
    "Q3. **How is Bayes' theorem used in practice?**\n",
    "Bayes' theorem is commonly used in statistics and machine learning for tasks such as classification, spam filtering, and medical diagnosis. It helps update probabilities based on new evidence or observations.\n",
    "\n",
    "Q4. **What is the relationship between Bayes' theorem and conditional probability?**\n",
    "Bayes' theorem is derived from conditional probability. It provides a way to calculate the probability of an event given prior knowledge of related events. The conditional probability \\( P(A|B) \\) is a key component in Bayes' theorem.\n",
    "\n",
    "Q5. **How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "The choice of a Naive Bayes classifier (e.g., Gaussian Naive Bayes, Multinomial Naive Bayes, or Bernoulli Naive Bayes) depends on the nature of the features in the dataset. Gaussian Naive Bayes is suitable for continuous numerical data, Multinomial Naive Bayes is used for discrete data (like word counts), and Bernoulli Naive Bayes is appropriate for binary data.\n",
    "\n",
    "Q6. **Naive Bayes Classification Assignment:**\n",
    "Let's calculate the probabilities for each class based on the given dataset:\n",
    "\n",
    "\\[ P(A) = P(B) = 0.5 \\]\n",
    "\n",
    "\\[ P(X1=3|A) = \\frac{4}{10} \\]\n",
    "\\[ P(X2=4|A) = \\frac{3}{10} \\]\n",
    "\n",
    "\\[ P(X1=3|B) = \\frac{1}{7} \\]\n",
    "\\[ P(X2=4|B) = \\frac{3}{7} \\]\n",
    "\n",
    "Now, apply Bayes' theorem:\n",
    "\n",
    "\\[ P(A|X1=3, X2=4) = \\frac{P(X1=3|A) \\cdot P(X2=4|A) \\cdot P(A)}{P(X1=3) \\cdot P(X2=4)} \\]\n",
    "\\[ P(B|X1=3, X2=4) = \\frac{P(X1=3|B) \\cdot P(X2=4|B) \\cdot P(B)}{P(X1=3) \\cdot P(X2=4)} \\]\n",
    "\n",
    "Since the prior probabilities are equal, we can compare \\( P(A|X1=3, X2=4) \\) and \\( P(B|X1=3, X2=4) \\) to determine the predicted class. The one with the higher probability is the predicted class.\n",
    "\n",
    "Calculating the probabilities, wecan determine which class the Naive Bayes classifier would predict for the given instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
