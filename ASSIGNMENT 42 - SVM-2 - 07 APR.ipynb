{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QUESTIONS`\n",
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ANSWERS`\n",
    "\n",
    "**Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?**\n",
    "\n",
    "Polynomial functions can be used as kernel functions in machine learning algorithms, especially in support vector machines (SVMs). In SVMs, the kernel function is responsible for transforming the input features into a higher-dimensional space, making it possible to find complex decision boundaries. The polynomial kernel is a specific type of kernel function.\n",
    "\n",
    "\n",
    "**Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?**\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create SVM classifier with polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3, coef0=1, C=1)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "This example uses the Iris dataset, splits it into training and testing sets, and trains an SVM classifier with a polynomial kernel. You can adjust parameters such as `degree` and `coef0` to explore different polynomial configurations.\n",
    "\n",
    "For the other questions, let's proceed with each one individually. Which one would you like to focus on next?\n",
    "\n",
    "**Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?**\n",
    "\n",
    "In Support Vector Regression (SVR), epsilon (\\(\\varepsilon\\)) is a hyperparameter that defines the margin of tolerance for errors in the regression prediction. Specifically, SVR aims to fit as many instances as possible within a margin of width \\(2\\varepsilon\\), where instances outside this margin contribute to the model's loss.\n",
    "\n",
    "Increasing the value of \\(\\varepsilon\\) allows for a wider margin, meaning that more data points can be within the margin without affecting the model's performance. Consequently, increasing \\(\\varepsilon\\) generally leads to an increase in the number of support vectors, as a larger margin allows more instances to be within the margin.\n",
    "\n",
    "**Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?**\n",
    "\n",
    "- **Kernel Function:**\n",
    "  - Choice: The kernel function determines the type of transformation applied to the input features. Common choices include linear, polynomial, and radial basis function (RBF) kernels.\n",
    "  - Example: Use RBF for capturing complex relationships, linear for simplicity.\n",
    "\n",
    "- **C Parameter:**\n",
    "  - Role: C is the regularization parameter that controls the trade-off between achieving a low training error and a low testing error. Smaller C values lead to a smoother decision boundary, allowing some misclassifications, while larger values aim for stricter fitting.\n",
    "  - Example: Increase C when you want a more precise fit to the training data.\n",
    "\n",
    "- **Epsilon Parameter:**\n",
    "  - Role: \\(\\varepsilon\\) defines the margin of tolerance for errors in regression prediction. Larger values allow a wider margin for fitting instances within the margin.\n",
    "  - Example: Increase \\(\\varepsilon\\) for a wider margin and tolerate more errors.\n",
    "\n",
    "- **Gamma Parameter:**\n",
    "  - Role: For RBF kernel, gamma defines the influence of a single training example. Smaller values make the influence broader, and larger values make it more localized.\n",
    "  - Example: Decrease gamma for a smoother decision boundary, increase for a more localized influence.\n",
    "\n",
    "**Q5. Assignment: Load the necessary libraries, split the dataset, preprocess the data, train an SVC classifier, evaluate performance, tune hyperparameters, train the tuned classifier, and save it to a file.**\n",
    "\n",
    "```\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data (e.g., scaling, normalization - not explicitly done here)\n",
    "\n",
    "# Create SVC classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'degree': [2, 3, 4]}\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_svm_classifier = SVC(**best_params)\n",
    "tuned_svm_classifier.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file\n",
    "joblib.dump(tuned_svm_classifier, 'tuned_svm_classifier.pkl')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
